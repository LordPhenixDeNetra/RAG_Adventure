# RAG Ultra Performant API

## üìã Description

Ce projet est une API RAG (Retrieval Augmented Generation) ultra-performante construite avec FastAPI. Elle int√®gre des techniques avanc√©es de recherche hybride, de re-ranking et d'optimisation pour fournir des r√©ponses pr√©cises et rapides √† partir de documents.

## ‚ú® Fonctionnalit√©s

- üîç **Recherche Hybride** : Combinaison de recherche dense (vectorielle) et sparse (BM25)
- üèÜ **Re-ranking** : Utilisation de Cross-Encoder pour am√©liorer la pertinence des r√©sultats
- üí° **Query Enhancement** : G√©n√©ration automatique de variantes de requ√™tes
- üóÑÔ∏è **Cache Multicouche** : Redis + m√©moire pour une performance optimale
- üìä **Monitoring** : M√©triques Prometheus int√©gr√©es
- ü§ñ **Multi-providers** : Support de plusieurs providers LLM (Mistral, OpenAI, Anthropic, Deepseek, Groq)
- ‚ö° **Streaming** : R√©ponses en temps r√©el
- üîß **Gestion avanc√©e des documents** : Chunking s√©mantique et m√©tadonn√©es enrichies

## üõ†Ô∏è Installation

### Pr√©requis

- Python 3.8+
- Redis (optionnel mais recommand√©)
- Cl√©s API pour les providers LLM souhait√©s

### Installation des d√©pendances

```bash
pip install -r requirements.txt
```

### Variables d'environnement

Cr√©ez un fichier `.env` √† la racine du projet :

```env
# Cl√©s API (selon les providers utilis√©s)
MISTRAL_API_KEY=votre_cle_mistral
OPENAI_API_KEY=votre_cle_openai
ANTHROPIC_API_KEY=votre_cle_anthropic
DEEPSEEK_API_KEY=votre_cle_deepseek
GROQ_API_KEY=votre_cle_groq

# Configuration Redis (optionnel)
REDIS_HOST=localhost
REDIS_PORT=6379

# Autres param√®tres
EMBEDDINGS_MODEL=all-mpnet-base-v2
RERANKER_MODEL=cross-encoder/ms-marco-MiniLM-L-12-v2
```

## üöÄ D√©marrage

### D√©veloppement

```bash
python main.py
```

### Production

```bash
uvicorn main:app --host 0.0.0.0 --port 8000 --workers 4
```

L'API sera accessible √† l'adresse : `http://localhost:8000`

## üìö API Endpoints

### üìÑ Documents

- `POST /upload-document` - T√©l√©verser un document (PDF, DOC, DOCX)
- `GET /documents-advanced` - Lister les documents avec m√©tadonn√©es
- `DELETE /documents/{document_id}` - Supprimer un document

### ‚ùì Questions

- `POST /ask-question-ultra` - Poser une question (mode standard)
- `POST /ask-question-stream-ultra` - Poser une question (mode streaming)

### üìä Monitoring

- `GET /health` - Statut de sant√© de l'API
- `GET /metrics` - M√©triques Prometheus
- `GET /performance-metrics` - M√©triques de performance d√©taill√©es
- `POST /clear-cache` - Vider le cache

## üîß Configuration avanc√©e

### Providers LLM support√©s

| Provider | Mod√®le par d√©faut | Statut |
|----------|-------------------|--------|
| Mistral | mistral-medium | ‚úÖ |
| OpenAI | gpt-4o-mini | ‚úÖ |
| Anthropic | claude-3-haiku-20240307 | ‚úÖ |
| Deepseek | deepseek-chat | ‚úÖ |
| Groq | mixtral-8x7b-32768 | ‚úÖ |

### Param√®tres de recherche

- `top_k`: Nombre de r√©sultats √† retourner (d√©faut: 3)
- `temperature`: Contr√¥le la cr√©ativit√© des r√©ponses (d√©faut: 0.3)
- `max_tokens`: Longueur maximale des r√©ponses (d√©faut: 512)

## üß© Architecture technique

### Composants principaux

1. **AdvancedEmbeddings** - Gestion des embeddings avec cache
2. **AdvancedChunker** - Chunking s√©mantique intelligent
3. **HybridSearch** - Recherche hybride dense + sparse
4. **AdvancedReranker** - Re-ranking avec Cross-Encoder
5. **QueryEnhancer** - Am√©lioration des requ√™tes
6. **OptimizedLLMProvider** - Abstraction multi-provider
7. **MultiLayerCache** - Cache multicouche Redis + m√©moire

### Flux de traitement

1. T√©l√©versement ‚Üí Chunking ‚Üí Stockage vectoriel
2. Requ√™te ‚Üí Enhancement ‚Üí Recherche hybride ‚Üí Re-ranking ‚Üí G√©n√©ration
3. R√©ponse ‚Üí Cache ‚Üí M√©triques

## üìä M√©triques et monitoring

L'API expose des m√©triques Prometheus pour :

- Temps de r√©ponse
- Taux de r√©ussite des requ√™tes
- Utilisation du cache
- Performance des providers
- Nombre de documents et chunks

## üîç Exemples d'utilisation

### T√©l√©verser un document

```bash
curl -X POST -F "file=@document.pdf" http://localhost:8000/upload-document
```

### Poser une question

```bash
# Utilisation de Mistral (par d√©faut)
curl -X POST -H "Content-Type: application/json" -d '{
  "question": "Quelle est la conclusion principale du document?",
  "provider": "mistral",
  "top_k": 3
}' http://localhost:8000/ask-question-ultra

# Utilisation d'OpenAI
curl -X POST -H "Content-Type: application/json" -d '{
  "question": "Quelle est la conclusion principale du document?",
  "provider": "openai",
  "top_k": 3
}' http://localhost:8000/ask-question-ultra

# Utilisation d'Anthropic
curl -X POST -H "Content-Type: application/json" -d '{
  "question": "Quelle est la conclusion principale du document?",
  "provider": "anthropic",
  "top_k": 3
}' http://localhost:8000/ask-question-ultra

# Utilisation de Deepseek
curl -X POST -H "Content-Type: application/json" -d '{
  "question": "Quelle est la conclusion principale du document?",
  "provider": "deepseek",
  "top_k": 3
}' http://localhost:8000/ask-question-ultra

# Utilisation de Groq
curl -X POST -H "Content-Type: application/json" -d '{
  "question": "Quelle est la conclusion principale du document?",
  "provider": "groq",
  "top_k": 3
}' http://localhost:8000/ask-question-ultra


```

### Obtenir les m√©triques

```bash
curl http://localhost:8000/metrics
```

## üö¶ Performance

### Optimisations

- Cache multicouche (Redis + m√©moire)
- Pr√©-chargement des mod√®les
- Traitement par batch
- Pool de threads pour op√©rations I/O
- Embedding caching avec LRU
- Indexation BM25 optimis√©e

### M√©triques cl√©s

- Temps de r√©ponse moyen : < 500ms
- Support de gros volumes de documents
- Cache hit rate > 70% avec Redis
- Faible consommation m√©moire

## üêõ D√©pannage

### Probl√®mes courants

1. **Redis non disponible** : Le syst√®me bascule sur le cache m√©moire
2. **Provider API inaccessible** : V√©rifiez les cl√©s API et la connectivit√©
3. **Documents non trouv√©s** : V√©rifiez le format des fichiers (PDF/DOC/DOCX)

### Logs

Les logs d√©taill√©s sont disponibles avec diff√©rents niveaux de verbosit√© :

```python
logging.basicConfig(level=logging.INFO)  # ou DEBUG pour plus de d√©tails
```

## ü§ù Contribuer

Les contributions sont les bienvenues ! Pour contribuer :

1. Fork le projet
2. Cr√©ez une branche feature (`git checkout -b feature/AmazingFeature`)
3. Commit vos changements (`git commit -m 'Add AmazingFeature'`)
4. Push vers la branche (`git push origin feature/AmazingFeature`)
5. Ouvrez une Pull Request

## üìù Licence

Ce projet est sous licence MIT. Voir le fichier `LICENSE` pour plus de d√©tails.

## üè∑Ô∏è Versions

- **v3.0.0** - Version ultra-performante avec recherche hybride et re-ranking
- **v2.0.0** - Support multi-provider et caching avanc√©
- **v1.0.0** - Version initiale avec fonctionnalit√©s de base RAG

## üìû Support

Pour toute question ou probl√®me, veuillez ouvrir une issue sur le repository GitHub.

---

**Note** : Cette API est con√ßue pour des environnements de production et inclut des fonctionnalit√©s avanc√©es de monitoring, caching et gestion d'erreurs.